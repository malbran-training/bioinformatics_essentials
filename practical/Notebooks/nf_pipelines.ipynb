{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nextflow Pipelines\n",
    "\n",
    "In this section we will download the `nf-core/bactmap` pipeline. We will apply this `nf-core/bactmap` pipeline to the data from the SNP Phylogeny tutorial and demonstrate how to use Nextflow Tower to track the progress of the pipeline run.\n",
    "\n",
    "But first, let's check that you're in the right place. Type the commands below in the terminal window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/course_data/bioinformatics_essentials/data\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should display something like:\n",
    "\n",
    "`/home/manager/course_data/bioinformatics_essentials/data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with Nextflow Tower\n",
    "\n",
    "Nextflow Tower is the centralized command post for managing and tracking Nextflow workflows. It has many features including the functionality to monitor the progress of your Nextflow pipeline runs via a web interface. \n",
    "\n",
    "Don't worry if this does not make sense initially, all will become clear once you run your first nextflow pipeline! For now follow the instructions below to set up and configure Nextflow Tower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to [https://cloud.tower.nf/](https://cloud.tower.nf/) and create an account and login into Tower.\n",
    "\n",
    "2. Create a new token by selecting `Your tokens` from the Settings drop-down menu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Create a token](img/usage_create_token.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Name your token, this can be anything you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Name the token](img/name2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Copy your new token into a text editor and put in a safe place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Save the token](img/usage_token.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Once your token has been created, open a terminal and type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export TOWER_ACCESS_TOKEN=eyxxxxxxxxxxxxxxxQ1ZTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where eyxxxxxxxxxxxxxxxQ1ZTE= is the token you have just created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a note to say that if you want this TOWER_ACCESS_TOKEN to be set permanently then you can edit a file called `.bashrc` in your home directory and add the above line to the end of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Nextflow Pipelines\n",
    "\n",
    "The `nf-core/bactmap` pipeline is a bioinformatics best-practice analysis pipeline for mapping short reads from bacterial WGS to a reference sequence, creating filtered VCF files, making pseudogenomes based on high quality positions in the VCF files and optionally creating a phylogeny from an alignment of the pseudogenomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bactmap Pipeline Summary](img/Bactmap_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we install any nf-core pipelines we must first set up a directory to hold the singularity containers for the software applications that used in the pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir ~/my_singularity\n",
    "export NXF_SINGULARITY_CACHEDIR=\"~/my_singularity\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install this `nf-core/bactmap` pipeline, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf-core download --compress none --container-system singularity \\\\\n",
    "--revision 1.0.0 bactmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may take some time to install. This command will download the nf-core pipeline called `bactmap`, the  options `--compress none` indicate how to compress the output, `--container singularity` specifies to download singularity container images for the required software and `--revision 1.0.0` specifies which version of bactmap to install."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the pipeline has installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls nf-core-bactmap_1.0.0/1_0_0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Nextflow Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have installed our first nextflow pipeline, let's run it on some data. First we need to consult the pipeline documentation to see how to run it. This can be found at [https://nf-co.re/bactmap/1.0.0/docs/usage/](https://nf-co.re/bactmap/1.0.0/docs/usage/). In summary, we need to create a samplesheet file with information about the samples in our experiment. This file has to be a comma-separated file with 3 columns, and a header row as shown in the example below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sample,fastq_1,fastq_2`   \n",
    "`G18582004,fastqs/G18582004_1.fastq.gz,fastqs/G18582004_2.fastq.gz`   \n",
    "`G18756254,fastqs/G18756254_1.fastq.gz,fastqs/G18756254_2.fastq.gz`   \n",
    "`G18582006,fastqs/G18582006_1.fastq.gz,fastqs/G18582006_2.fastq.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the bactmap pipeline on our samples from the snp-phylogeny tutorial. To get you started we have already created a samplesheet file for this data. Take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat samplesheet.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the `nf-core/bactmap` pipeline with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextflow run nf-core-bactmap_1.0.0/1_0_0/main.nf \\\n",
    "--input samplesheet.csv \\\n",
    "--outdir my_results \\\n",
    "--reference chromosome.fasta \\\n",
    "--iqtree \\\n",
    "-w my_results/work \\\n",
    "-profile singularity \\\n",
    "-resume \\\n",
    "-with-tower "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline steps are written in the nextflow language and are found in the file `nf-core-bactmap_1.0.0/1_0_0/main.nf`. Let's look at the options, these can be seperated into two types. \n",
    "\n",
    "The first set of options (starting with `--`) are specific to the `nf-core/bactmap` pipeline:\n",
    "\n",
    "* `--input` specifies the samplesheet.csv file that contains the fastq file information for our samples   \n",
    "* `--output` specifies the output where the results from the pipeline will be saved    \n",
    "* `--reference` specifies a fasta file of the reference sequence  \n",
    "* `--iqtree` specifies to build a tree using the IQ-TREE  \n",
    "\n",
    "The full set of parameters for the bactmap pipeline can be found at [https://nf-co.re/bactmap/1.0.0/parameters/](https://nf-co.re/bactmap/1.0.0/parameters/).\n",
    "\n",
    "The second set of options (starting with `-`) are specific to the nextflow engine:\n",
    "\n",
    "* `-w` option tells nextflow where to store the intermediate files produced by the pipeline   \n",
    "* `-profile` option tells nextflow to use the singularity profile   \n",
    "* `-resume` option tells nextflow to run the script using the cached results  \n",
    "* `-with-tower` option tells nextflow to send information about the pipeline run to Nextflow Tower using the TOWER_ACCESS_TOKEN set earlier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nextflow profiles\n",
    "\n",
    "A profile is a set of configuration attributes that can be activated/chosen when running a pipeline. One use of a profile is to define a set of attributes specific to where you are running the pipeline e.g. singularity here tells Nextflow to run the pipeline locally using Singularity containers. \n",
    "\n",
    "There are a range of pre-configured profiles to use with nf-core pipelines. If you were running the pipeline on a commercial cloud platform (e.g. google or amazon) you could use the specific profile for that platform (e.g. google or aws). If you were running the pipeline on a compute cluster at your institute (e.g. Sanger or Cambridge University) you could use an institute specific profile provided someone has implemented one in nf-core (e.g. sanger or cambridge). A list of available institute profiles can be found at [https://github.com/nf-core/configs/](https://github.com/nf-core/configs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nextflow resume\n",
    "\n",
    "A very useful feature of Nextflow is the `--resume` option that can be used to re-start a pipeline if it fails. This will cache any steps of the pipeline that run succesfully. When you fix the problem with your data and re-run the pipeline it will not run all of the steps from the beginning but instead it will start from the last failed step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nextflow tower\n",
    "\n",
    "You should be able to monitor your Nextflow jobs in Nextflow Tower. So go back to the Nextflow Tower website and see if you can find your pipeline run on the website. Nextflow Tower is extremely powerful, if you have time explore the interface for your pipeline run. Notice it lists all the steps of a pipeline run, the commands involved in each step and tracks the compute resources (cpu time and memory) for the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Nextflow Tower](img/tower.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nextflow Tips\n",
    "\n",
    "* Always take note of where you launced a nextflow pipeline from, pipeline progress will be stored in a hidden file called `.nextflow` in that directory\n",
    "* If running more than one nextflow pipeline at a time make sure to launch or start them from different directories\n",
    "* Remember to delete the work directory if the pipeline was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations you have just successfully installed and run a nextflow pipeline!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
